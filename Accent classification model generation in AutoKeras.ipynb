{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-09-06T15:31:53.286945Z",
     "iopub.status.busy": "2021-09-06T15:31:53.286634Z",
     "iopub.status.idle": "2021-09-06T15:33:14.040204Z",
     "shell.execute_reply": "2021-09-06T15:33:14.03928Z",
     "shell.execute_reply.started": "2021-09-06T15:31:53.286915Z"
    }
   },
   "outputs": [],
   "source": [
    "!pip install git+https://github.com/keras-team/keras-tuner.git\n",
    "!pip install autokeras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-06T15:33:14.043927Z",
     "iopub.status.busy": "2021-09-06T15:33:14.043656Z",
     "iopub.status.idle": "2021-09-06T15:33:15.888318Z",
     "shell.execute_reply": "2021-09-06T15:33:15.887419Z",
     "shell.execute_reply.started": "2021-09-06T15:33:14.043897Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import librosa\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import autokeras\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['figure.dpi'] = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-952b80a00d81>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfilename\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdirectory1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"mp3.wav\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m         \u001b[0mstep\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_wav\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m40000\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m         \u001b[0mlis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-4-952b80a00d81>\u001b[0m in \u001b[0;36mget_wav\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m      4\u001b[0m     '''\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlibrosa\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdirectory1\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'/'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[1;32mreturn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlibrosa\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0morig_sr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msr\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtarget_sr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscale\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\librosa\\core\\audio.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(path, sr, mono, offset, duration, dtype, res_type)\u001b[0m\n\u001b[0;32m    173\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    174\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0msr\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 175\u001b[1;33m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msr_native\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mres_type\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mres_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    176\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    177\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\librosa\\core\\audio.py\u001b[0m in \u001b[0;36mresample\u001b[1;34m(y, orig_sr, target_sr, res_type, fix, scale, **kwargs)\u001b[0m\n\u001b[0;32m    602\u001b[0m         \u001b[0my_hat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msoxr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morig_sr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_sr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mquality\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mres_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    603\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 604\u001b[1;33m         \u001b[0my_hat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresampy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morig_sr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_sr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mres_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    605\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    606\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfix\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\resampy\\core.py\u001b[0m in \u001b[0;36mresample\u001b[1;34m(x, sr_orig, sr_new, axis, filter, **kwargs)\u001b[0m\n\u001b[0;32m    118\u001b[0m     \u001b[0mx_2d\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mswapaxes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m     \u001b[0my_2d\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mswapaxes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 120\u001b[1;33m     \u001b[0mresample_f\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_2d\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_2d\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_ratio\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minterp_win\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minterp_delta\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprecision\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    121\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def get_wav(path):\n",
    "    '''\n",
    "    Load wav file from disk and down-samples to RATE\n",
    "    '''\n",
    "\n",
    "    y, sr = librosa.load(directory1+'/'+path)\n",
    "    return(librosa.core.resample(y=y,orig_sr=sr,target_sr=sr, scale=True),sr)\n",
    "\n",
    "lis = []\n",
    "directory1 = 'C:/Users/Ahmed/Desktop/dissertation/archive/recordings/recordings_wave'\n",
    "for filename in os.listdir(directory1):\n",
    "    if filename.endswith(\"mp3.wav\"):\n",
    "        step = get_wav(filename)[:40000]\n",
    "        lis.append(step)\n",
    "        \n",
    "Audio_data = pd.Dataframe(lis)\n",
    "Audio_data.to_csv(\"wave.csv\", sep=',',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-06T15:33:15.890499Z",
     "iopub.status.busy": "2021-09-06T15:33:15.890166Z",
     "iopub.status.idle": "2021-09-06T15:37:56.145392Z",
     "shell.execute_reply": "2021-09-06T15:37:56.144226Z",
     "shell.execute_reply.started": "2021-09-06T15:33:15.89046Z"
    }
   },
   "outputs": [],
   "source": [
    "Audio = pd.read_csv('../input/wave-data/wave.csv')\n",
    "labels_binary = pd.read_csv('../input/labels/labels.csv')\n",
    "labels_multi = pd.read_csv('../input/labels/labels_5.csv')\n",
    "                           \n",
    "def to_mfcc(wav):\n",
    "\n",
    "    return(librosa.feature.mfcc(y=wav, sr=22050))\n",
    "\n",
    "mfccs = []\n",
    "for i in range(len(Audio)):\n",
    "    mfcc = to_mfcc(np.array(Audio.iloc[i]))  \n",
    "    mfccs.append(mfcc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "GPU device not found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-2a4e6d434881>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m## GPU needed for AutoKeras\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mdevice_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgpu_device_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32massert\u001b[0m \u001b[0mdevice_name\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'/device:GPU:0'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'GPU device not found'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlist_physical_devices\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'GPU'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAssertionError\u001b[0m: GPU device not found"
     ]
    }
   ],
   "source": [
    "## GPU needed for AutoKeras\n",
    "device_name = tf.test.gpu_device_name()\n",
    "assert device_name == '/device:GPU:0', 'GPU device not found'\n",
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BINARY MODELS USING AUTOKERAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-04T22:37:02.712387Z",
     "iopub.status.busy": "2021-09-04T22:37:02.712018Z",
     "iopub.status.idle": "2021-09-04T22:44:01.528686Z",
     "shell.execute_reply": "2021-09-04T22:44:01.527827Z",
     "shell.execute_reply.started": "2021-09-04T22:37:02.712355Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "X = np.asarray(mfccs).astype('float32')\n",
    "y = LabelEncoder().fit_transform(labels_binary)\n",
    "# separate into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle = True, stratify = y)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.125, random_state=42, shuffle = True, stratify = y_train)\n",
    "\n",
    "rows = np.array(X_train)[0].shape[0]\n",
    "cols = np.array(X_train)[0].shape[1]\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0], rows,cols)\n",
    "class_weights = {0: 0.38564555,\n",
    "                1: 1.84665227}\n",
    "\n",
    "input_node = .Input()\n",
    "output_node = autokeras.DenseBlock()(input_node)\n",
    "output_node = autokeras.ClassificationHead()(output_node)\n",
    "\n",
    "\n",
    "clf = autokeras.AutoModel(\n",
    "    inputs=input_node, outputs=output_node, overwrite=True, max_trials=100\n",
    ")\n",
    "history= clf.fit(X_train, y_train, epochs=50, validation_data=(X_val, y_val))\n",
    "\n",
    "plt.plot(history.history['accuracy'])  \n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('English vs None-English accent accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "loss, acc = clf.evaluate(X_test, y_test, verbose=True)\n",
    "print('Accuracy: %.3f' % acc)\n",
    "model = clf.export_model()\n",
    "\n",
    "rows = np.array(X_test[0]).shape[0]\n",
    "cols = np.array(X_test[0]).shape[1]\n",
    "X_test = np.asarray(X_test).reshape(np.asarray(X_test).shape[0], rows, cols )\n",
    "y_test = y_test.astype(float)\n",
    "predictions =  np.round(model.predict(np.array(X_test).astype(float)))\n",
    "    \n",
    "print('test accuracy = ',accuracy_score(y_test, np.asarray(predictions)))\n",
    "print('test precision = ',precision_score(y_test, predictions, average='weighted'))\n",
    "print('test recall = ',recall_score(y_test, predictions, average='weighted'))\n",
    "print('test f1 = ',f1_score(y_test, predictions, average='macro'))\n",
    "print('matthsew correlation = ',matthews_corrcoef(y_test, predictions))\n",
    "cf = confusion_matrix(y_test, predictions)\n",
    "ax= plt.subplot()\n",
    "sns.heatmap(cf, annot=True, fmt='g', ax=ax);  \n",
    "ax.set_xlabel('Predicted labels');ax.set_ylabel('True labels'); \n",
    "ax.set_title('Confusion Matrix'); \n",
    "ax.xaxis.set_ticklabels(['English ', 'None English ']); ax.yaxis.set_ticklabels(['English ', 'None English ']);\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.save('autokeras_binary_MLP.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-04T22:49:07.913329Z",
     "iopub.status.busy": "2021-09-04T22:49:07.912879Z",
     "iopub.status.idle": "2021-09-04T22:49:07.948925Z",
     "shell.execute_reply": "2021-09-04T22:49:07.948115Z",
     "shell.execute_reply.started": "2021-09-04T22:49:07.91329Z"
    }
   },
   "outputs": [],
   "source": [
    "model.save('autokeras_binary_MLP_FINAL.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-04T22:49:09.748343Z",
     "iopub.status.busy": "2021-09-04T22:49:09.747975Z",
     "iopub.status.idle": "2021-09-04T23:14:43.927481Z",
     "shell.execute_reply": "2021-09-04T23:14:43.926607Z",
     "shell.execute_reply.started": "2021-09-04T22:49:09.748312Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "X = np.asarray(mfccs).astype('float32')\n",
    "y = LabelEncoder().fit_transform(labels_binary)\n",
    "# separate into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle = True, stratify = y)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.125, random_state=42, shuffle = True, stratify = y_train)\n",
    "\n",
    "rows = np.array(X_train)[0].shape[0]\n",
    "cols = np.array(X_train)[0].shape[1]\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0], rows,cols,1)\n",
    "class_weights = {0: 0.38564555,\n",
    "                1: 1.84665227}\n",
    "\n",
    "input_node = .Input()\n",
    "output_node = autokeras.ConvBlock()(input_node)\n",
    "output_node = autokeras.DenseBlock()(output_node)\n",
    "output_node = autokeras.ClassificationHead()(output_node)\n",
    "\n",
    "\n",
    "clf = autokeras.AutoModel(\n",
    "    inputs=input_node, outputs=output_node, overwrite=True, max_trials=100\n",
    ")\n",
    "history= clf.fit(X_train, y_train, epochs=100, validation_data=(X_val, y_val))\n",
    "\n",
    "plt.plot(history.history['accuracy'])  \n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('English vs None-English accent accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "loss, acc = clf.evaluate(X_test, y_test, verbose=True)\n",
    "print('Accuracy: %.3f' % acc)\n",
    "model = clf.export_model()\n",
    "\n",
    "rows = np.array(X_test[0]).shape[0]\n",
    "cols = np.array(X_test[0]).shape[1]\n",
    "X_test = np.asarray(X_test).reshape(np.asarray(X_test).shape[0], rows, cols )\n",
    "y_test = y_test.astype(float)\n",
    "predictions =  np.round(model.predict(np.array(X_test).astype(float)))\n",
    "    \n",
    "print('test accuracy = ',accuracy_score(y_test, np.asarray(predictions)))\n",
    "print('test precision = ',precision_score(y_test, predictions, average='weighted'))\n",
    "print('test recall = ',recall_score(y_test, predictions, average='weighted'))\n",
    "print('test f1 = ',f1_score(y_test, predictions, average='macro'))\n",
    "print('matthsew correlation = ',matthews_corrcoef(y_test, predictions))\n",
    "cf = confusion_matrix(y_test, predictions)\n",
    "ax= plt.subplot()\n",
    "sns.heatmap(cf, annot=True, fmt='g', ax=ax);  \n",
    "ax.set_xlabel('Predicted labels');ax.set_ylabel('True labels'); \n",
    "ax.set_title('Confusion Matrix'); \n",
    "ax.xaxis.set_ticklabels(['None English ', 'English ']); ax.yaxis.set_ticklabels(['None English', 'English ']);\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.save('autokeras_binary_CNN.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-04T23:20:29.442648Z",
     "iopub.status.busy": "2021-09-04T23:20:29.442181Z",
     "iopub.status.idle": "2021-09-04T23:20:29.475001Z",
     "shell.execute_reply": "2021-09-04T23:20:29.474137Z",
     "shell.execute_reply.started": "2021-09-04T23:20:29.44261Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "model.save('autokeras_binary_CNN_FINAL.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-06T16:17:11.38887Z",
     "iopub.status.busy": "2021-09-06T16:17:11.388501Z",
     "iopub.status.idle": "2021-09-06T16:35:49.95461Z",
     "shell.execute_reply": "2021-09-06T16:35:49.953841Z",
     "shell.execute_reply.started": "2021-09-06T16:17:11.38884Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "X = np.asarray(mfccs).astype('float32')\n",
    "y = LabelEncoder().fit_transform(labels_binary)\n",
    "# separate into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle = True, stratify = y)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.125, random_state=42, shuffle = True, stratify = y_train)\n",
    "\n",
    "rows = np.array(X_train)[0].shape[0]\n",
    "cols = np.array(X_train)[0].shape[1]\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0], rows,cols)\n",
    "\n",
    "class_weights = {0: 0.38564555,\n",
    "                1: 1.84665227}\n",
    "\n",
    "input_node = autokeras.Input()\n",
    "output_node = autokeras.RNNBlock(bidirectional=False)(input_node)\n",
    "output_node = autokeras.DenseBlock()(output_node)\n",
    "output_node = autokeras.ClassificationHead()(output_node)\n",
    "\n",
    "\n",
    "clf = autokeras.AutoModel(\n",
    "    inputs=input_node, outputs=output_node, overwrite=True, max_trials=100\n",
    ")\n",
    "history= clf.fit(X_train, y_train, epochs=100, validation_data=(X_val, y_val))\n",
    "\n",
    "plt.plot(history.history['accuracy'])  \n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('English vs None-English accent accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "loss, acc = clf.evaluate(X_test, y_test, verbose=True)\n",
    "print('Accuracy: %.3f' % acc)\n",
    "model = clf.export_model()\n",
    "\n",
    "rows = np.array(X_test[0]).shape[0]\n",
    "cols = np.array(X_test[0]).shape[1]\n",
    "X_test = np.asarray(X_test).reshape(np.asarray(X_test).shape[0], rows, cols )\n",
    "y_test = y_test.astype(float)\n",
    "predictions =  np.round(model.predict(np.array(X_test).astype(float)))\n",
    "    \n",
    "print('test accuracy = ',accuracy_score(y_test, np.asarray(predictions)))\n",
    "print('test precision = ',precision_score(y_test, predictions, average='weighted'))\n",
    "print('test recall = ',recall_score(y_test, predictions, average='weighted'))\n",
    "print('test f1 = ',f1_score(y_test, predictions, average='macro'))\n",
    "print('matthsew correlation = ',matthews_corrcoef(y_test, predictions))\n",
    "cf = confusion_matrix(y_test, predictions)\n",
    "ax= plt.subplot()\n",
    "sns.heatmap(cf, annot=True, fmt='g', ax=ax);  \n",
    "ax.set_xlabel('Predicted labels');ax.set_ylabel('True labels'); \n",
    "ax.set_title('Confusion Matrix'); \n",
    "ax.xaxis.set_ticklabels(['None English ', 'English ']); ax.yaxis.set_ticklabels(['None English', 'English ']);\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.save('autokeras_binary_RNN.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-05T00:29:57.088007Z",
     "iopub.status.busy": "2021-09-05T00:29:57.08763Z",
     "iopub.status.idle": "2021-09-05T00:29:57.122216Z",
     "shell.execute_reply": "2021-09-05T00:29:57.121464Z",
     "shell.execute_reply.started": "2021-09-05T00:29:57.087974Z"
    }
   },
   "outputs": [],
   "source": [
    "model.save('autokeras_binary_RNN_FINAL.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-05T11:30:58.163793Z",
     "iopub.status.busy": "2021-09-05T11:30:58.163058Z",
     "iopub.status.idle": "2021-09-05T12:24:25.549288Z",
     "shell.execute_reply": "2021-09-05T12:24:25.548123Z",
     "shell.execute_reply.started": "2021-09-05T11:30:58.163743Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "X = np.asarray(mfccs).astype('float32')\n",
    "y = LabelEncoder().fit_transform(labels_binary)\n",
    "# separate into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle = True, stratify = y)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.125, random_state=42, shuffle = True, stratify = y_train)\n",
    "\n",
    "rows = np.array(X_train)[0].shape[0]\n",
    "cols = np.array(X_train)[0].shape[1]\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0], rows,cols)\n",
    "class_weights = {0: 0.38564555,\n",
    "                1: 1.84665227}\n",
    "\n",
    "input_node = autokeras.Input()\n",
    "output_node = autokeras.ConvBlock()(input_node)\n",
    "output_node = autokeras.RNNBlock()(output_node)\n",
    "output_node = autokeras.DenseBlock()(output_node)\n",
    "output_node = autokeras.ClassificationHead()(output_node)\n",
    "\n",
    "\n",
    "clf = autokeras.AutoModel(\n",
    "    inputs=input_node, outputs=output_node, overwrite=True, max_trials=100\n",
    ")\n",
    "history= clf.fit(X_train, y_train, epochs=100, validation_data=(X_val, y_val))\n",
    "\n",
    "plt.plot(history.history['accuracy'])  \n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('English vs None-English accent accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "loss, acc = clf.evaluate(X_test, y_test, verbose=True)\n",
    "print('Accuracy: %.3f' % acc)\n",
    "model = clf.export_model()\n",
    "\n",
    "rows = np.array(X_test[0]).shape[0]\n",
    "cols = np.array(X_test[0]).shape[1]\n",
    "X_test = np.asarray(X_test).reshape(np.asarray(X_test).shape[0], rows, cols )\n",
    "y_test = y_test.astype(float)\n",
    "predictions =  np.round(model.predict(np.array(X_test).astype(float)))\n",
    "    \n",
    "print('test accuracy = ',accuracy_score(y_test, np.asarray(predictions)))\n",
    "print('test precision = ',precision_score(y_test, predictions, average='weighted'))\n",
    "print('test recall = ',recall_score(y_test, predictions, average='weighted'))\n",
    "print('test f1 = ',f1_score(y_test, predictions, average='macro'))\n",
    "print('matthsew correlation = ',matthews_corrcoef(y_test, predictions))\n",
    "cf = confusion_matrix(y_test, predictions)\n",
    "ax= plt.subplot()\n",
    "sns.heatmap(cf, annot=True, fmt='g', ax=ax);  \n",
    "ax.set_xlabel('Predicted labels');ax.set_ylabel('True labels'); \n",
    "ax.set_title('Confusion Matrix'); \n",
    "ax.xaxis.set_ticklabels(['None English ', 'English ']); ax.yaxis.set_ticklabels(['None English', 'English ']);\n",
    "\n",
    "model.summary()\n",
    "\n",
    "\n",
    "model.save('autokeras_binary_Transformer.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-05T12:24:40.073262Z",
     "iopub.status.busy": "2021-09-05T12:24:40.072854Z",
     "iopub.status.idle": "2021-09-05T12:24:40.123653Z",
     "shell.execute_reply": "2021-09-05T12:24:40.122525Z",
     "shell.execute_reply.started": "2021-09-05T12:24:40.073229Z"
    }
   },
   "outputs": [],
   "source": [
    "model.save('autokeras_binary_Transformer_FINAL.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## MULTI - CLASS MODELS USING AUTOKERAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-05T12:56:37.936664Z",
     "iopub.status.busy": "2021-09-05T12:56:37.936243Z",
     "iopub.status.idle": "2021-09-05T13:14:01.74299Z",
     "shell.execute_reply": "2021-09-05T13:14:01.741889Z",
     "shell.execute_reply.started": "2021-09-05T12:56:37.936628Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "X = np.asarray(mfccs).astype('float32')\n",
    "y = LabelEncoder().fit_transform(labels_multi)\n",
    "\n",
    "\n",
    "# separate into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle = True, stratify = y)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.125, random_state=42, shuffle = True, stratify = y_train)\n",
    "\n",
    "rows = np.array(X_train)[0].shape[0]\n",
    "cols = np.array(X_train)[0].shape[1]\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0], rows,cols)\n",
    "# class_weights = {0: 0.30546624,\n",
    "#                     1: 0.61555076,\n",
    "#                     2: 2.19230769,\n",
    "#                     3: 3.47560976,\n",
    "#                     4: 5.48076923,\n",
    "#                     5: 5.7 }\n",
    "\n",
    "input_node = autokeras.Input()\n",
    "output_node = autokeras.DenseBlock()(input_node)\n",
    "output_node = autokeras.ClassificationHead()(output_node)\n",
    "\n",
    "\n",
    "clf = autokeras.AutoModel(\n",
    "    inputs=input_node, outputs=output_node, overwrite=True, max_trials=100\n",
    ")\n",
    "history= clf.fit(X_train, y_train, epochs=100, validation_data=(X_val, y_val) )\n",
    "\n",
    "plt.plot(history.history['accuracy'])  \n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('English vs None-English accent accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "loss, acc = clf.evaluate(X_test, y_test, verbose=True)\n",
    "print('Accuracy: %.3f' % acc)\n",
    "model = clf.export_model()\n",
    "\n",
    "rows = np.array(X_test[0]).shape[0]\n",
    "cols = np.array(X_test[0]).shape[1]\n",
    "X_test = np.asarray(X_test).reshape(np.asarray(X_test).shape[0], rows, cols, 1 )\n",
    "y_test = y_test.astype(float)\n",
    "predictions =  np.argmax(model.predict(np.array(X_test).astype(float)), axis=1)\n",
    "\n",
    "\n",
    "\n",
    "print('test accuracy = ',accuracy_score(y_test, predictions))\n",
    "print('test precision = ',precision_score(y_test, predictions, average='weighted'))\n",
    "print('test recall = ',recall_score(y_test, predictions, average='weighted'))\n",
    "print('test f1 = ',f1_score(y_test, predictions, average='macro'))\n",
    "print('matthsew correlation = ',matthews_corrcoef(y_test, predictions))\n",
    "\n",
    "cf = confusion_matrix(y_test, predictions)\n",
    "ax= plt.subplot()\n",
    "sns.heatmap(cf, annot=True, fmt='g', ax=ax);  \n",
    "ax.set_xlabel('Predicted labels');ax.set_ylabel('True labels'); \n",
    "ax.set_title('Confusion Matrix'); \n",
    "ax.xaxis.set_ticklabels(['Arabic', 'English','French', 'Mandarin','Other','Spanish']); ax.yaxis.set_ticklabels(['Arabic', 'English','french', 'mandarin','other','spanish'], rotation=45);\n",
    "\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.save('autokeras_multi_MLP.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-05T13:21:00.448841Z",
     "iopub.status.busy": "2021-09-05T13:21:00.448411Z",
     "iopub.status.idle": "2021-09-05T13:21:00.493675Z",
     "shell.execute_reply": "2021-09-05T13:21:00.492463Z",
     "shell.execute_reply.started": "2021-09-05T13:21:00.448792Z"
    }
   },
   "outputs": [],
   "source": [
    "model.save('autokeras_multi_MLP_FINAL.h5')\n",
    "# other = 4\n",
    "#arabic  = 0\n",
    "# english =1\n",
    "#spanish =5\n",
    "# mandarin = 3\n",
    "# french =2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-05T13:22:17.841754Z",
     "iopub.status.busy": "2021-09-05T13:22:17.841372Z",
     "iopub.status.idle": "2021-09-05T14:01:37.056553Z",
     "shell.execute_reply": "2021-09-05T14:01:37.055137Z",
     "shell.execute_reply.started": "2021-09-05T13:22:17.841721Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "X = np.asarray(mfccs).astype('float32')\n",
    "y = LabelEncoder().fit_transform(labels_multi)\n",
    "\n",
    "\n",
    "# separate into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle = True, stratify = y)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.125, random_state=42, shuffle = True, stratify = y_train)\n",
    "\n",
    "rows = np.array(X_train)[0].shape[0]\n",
    "cols = np.array(X_train)[0].shape[1]\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0], rows,cols)\n",
    "# class_weights = {0: 0.30546624,\n",
    "#                     1: 0.61555076,\n",
    "#                     2: 2.19230769,\n",
    "#                     3: 3.47560976,\n",
    "#                     4: 5.48076923,\n",
    "#                     5: 5.7 }\n",
    "\n",
    "input_node = autokeras.Input()\n",
    "output_node = autokeras.ConvBlock()(input_node)\n",
    "output_node = autokeras.DenseBlock()(output_node)\n",
    "output_node = autokeras.ClassificationHead()(output_node)\n",
    "\n",
    "\n",
    "clf = autokeras.AutoModel(\n",
    "    inputs=input_node, outputs=output_node, overwrite=True, max_trials=100\n",
    ")\n",
    "history= clf.fit(X_train, y_train, epochs=100, validation_data=(X_val, y_val) )\n",
    "\n",
    "plt.plot(history.history['accuracy'])  \n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('English vs None-English accent accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "loss, acc = clf.evaluate(X_test, y_test, verbose=True)\n",
    "print('Accuracy: %.3f' % acc)\n",
    "model = clf.export_model()\n",
    "\n",
    "rows = np.array(X_test[0]).shape[0]\n",
    "cols = np.array(X_test[0]).shape[1]\n",
    "X_test = np.asarray(X_test).reshape(np.asarray(X_test).shape[0], rows, cols, 1 )\n",
    "y_test = y_test.astype(float)\n",
    "predictions =  np.argmax(model.predict(np.array(X_test).astype(float)), axis=1)\n",
    "\n",
    "\n",
    "\n",
    "print('test accuracy = ',accuracy_score(y_test, predictions))\n",
    "print('test precision = ',precision_score(y_test, predictions, average='weighted'))\n",
    "print('test recall = ',recall_score(y_test, predictions, average='weighted'))\n",
    "print('test f1 = ',f1_score(y_test, predictions, average='macro'))\n",
    "print('matthsew correlation = ',matthews_corrcoef(y_test, predictions))\n",
    "\n",
    "cf = confusion_matrix(y_test, predictions)\n",
    "ax= plt.subplot()\n",
    "sns.heatmap(cf, annot=True, fmt='g', ax=ax);  \n",
    "ax.set_xlabel('Predicted labels');ax.set_ylabel('True labels'); \n",
    "ax.set_title('Confusion Matrix'); \n",
    "ax.xaxis.set_ticklabels(['Arabic', 'English','French', 'Mandarin','Other','Spanish']); ax.yaxis.set_ticklabels(['Arabic', 'English','french', 'mandarin','other','spanish'], rotation=45);\n",
    "\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.save('autokeras_multi_CNN.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-05T14:04:56.728121Z",
     "iopub.status.busy": "2021-09-05T14:04:56.727637Z",
     "iopub.status.idle": "2021-09-05T14:04:56.770542Z",
     "shell.execute_reply": "2021-09-05T14:04:56.769515Z",
     "shell.execute_reply.started": "2021-09-05T14:04:56.728089Z"
    }
   },
   "outputs": [],
   "source": [
    "model.save('autokeras_multi_CNN_FINAL.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-05T15:12:07.812325Z",
     "iopub.status.busy": "2021-09-05T15:12:07.811866Z",
     "iopub.status.idle": "2021-09-05T15:46:57.540383Z",
     "shell.execute_reply": "2021-09-05T15:46:57.536985Z",
     "shell.execute_reply.started": "2021-09-05T15:12:07.812285Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "X = np.asarray(mfccs).astype('float32')\n",
    "y = LabelEncoder().fit_transform(labels_multi)\n",
    "\n",
    "\n",
    "# separate into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle = True, stratify = y)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.125, random_state=42, shuffle = True, stratify = y_train)\n",
    "\n",
    "rows = np.array(X_train)[0].shape[0]\n",
    "cols = np.array(X_train)[0].shape[1]\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0], rows,cols)\n",
    "# class_weights = {0: 0.30546624,\n",
    "#                     1: 0.61555076,\n",
    "#                     2: 2.19230769,\n",
    "#                     3: 3.47560976,\n",
    "#                     4: 5.48076923,\n",
    "#                     5: 5.7 }\n",
    "\n",
    "input_node = autokeras.Input()\n",
    "output_node = autokeras.RNNBlock()(input_node)\n",
    "output_node = autokeras.DenseBlock()(output_node)\n",
    "output_node = autokeras.ClassificationHead()(output_node)\n",
    "\n",
    "\n",
    "clf = autokeras.AutoModel(\n",
    "    inputs=input_node, outputs=output_node, overwrite=True, max_trials=100\n",
    ")\n",
    "history= clf.fit(X_train, y_train, epochs=100, validation_data=(X_val, y_val) )\n",
    "\n",
    "plt.plot(history.history['accuracy'])  \n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('English vs None-English accent accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "loss, acc = clf.evaluate(X_test, y_test, verbose=True)\n",
    "print('Accuracy: %.3f' % acc)\n",
    "model = clf.export_model()\n",
    "\n",
    "rows = np.array(X_test[0]).shape[0]\n",
    "cols = np.array(X_test[0]).shape[1]\n",
    "X_test = np.asarray(X_test).reshape(np.asarray(X_test).shape[0], rows, cols, 1 )\n",
    "y_test = y_test.astype(float)\n",
    "predictions =  np.argmax(model.predict(np.array(X_test).astype(float)), axis=1)\n",
    "\n",
    "\n",
    "\n",
    "print('test accuracy = ',accuracy_score(y_test, predictions))\n",
    "print('test precision = ',precision_score(y_test, predictions, average='weighted'))\n",
    "print('test recall = ',recall_score(y_test, predictions, average='weighted'))\n",
    "print('test f1 = ',f1_score(y_test, predictions, average='macro'))\n",
    "print('matthsew correlation = ',matthews_corrcoef(y_test, predictions))\n",
    "\n",
    "cf = confusion_matrix(y_test, predictions)\n",
    "ax= plt.subplot()\n",
    "sns.heatmap(cf, annot=True, fmt='g', ax=ax);  \n",
    "ax.set_xlabel('Predicted labels');ax.set_ylabel('True labels'); \n",
    "ax.set_title('Confusion Matrix'); \n",
    "ax.xaxis.set_ticklabels(['Arabic', 'English','French', 'Mandarin','Other','Spanish']); ax.yaxis.set_ticklabels(['Arabic', 'English','french', 'mandarin','other','spanish'], rotation=45);\n",
    "\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.save('autokeras_multi_RNN.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-05T15:57:08.517Z",
     "iopub.status.busy": "2021-09-05T15:57:08.516646Z",
     "iopub.status.idle": "2021-09-05T15:57:08.550011Z",
     "shell.execute_reply": "2021-09-05T15:57:08.549113Z",
     "shell.execute_reply.started": "2021-09-05T15:57:08.516969Z"
    }
   },
   "outputs": [],
   "source": [
    "model.save('autokeras_multi_RNN_FINAL.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-05T17:16:08.855404Z",
     "iopub.status.busy": "2021-09-05T17:16:08.855061Z",
     "iopub.status.idle": "2021-09-05T18:02:32.079457Z",
     "shell.execute_reply": "2021-09-05T18:02:32.078605Z",
     "shell.execute_reply.started": "2021-09-05T17:16:08.85537Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "X = np.asarray(mfccs).astype('float32')\n",
    "y = LabelEncoder().fit_transform(labels_multi)\n",
    "\n",
    "\n",
    "# separate into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle = True, stratify = y)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.125, random_state=42, shuffle = True, stratify = y_train)\n",
    "\n",
    "rows = np.array(X_train)[0].shape[0]\n",
    "cols = np.array(X_train)[0].shape[1]\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0], rows,cols)\n",
    "class_weights = {0: 0.30546624,\n",
    "                    1: 0.61555076,\n",
    "                    2: 2.19230769,\n",
    "                    3: 3.47560976,\n",
    "                    4: 5.48076923,\n",
    "                    5: 5.7 }\n",
    "\n",
    "input_node = .Input()\n",
    "output_node = autokeras.ConvBlock()(input_node)\n",
    "output_node = autokeras.RNNBlock()(output_node)\n",
    "output_node = autokeras.DenseBlock()(output_node)\n",
    "output_node = autokeras.ClassificationHead()(output_node)\n",
    "\n",
    "\n",
    "clf = autokeras.AutoModel(\n",
    "    inputs=input_node, outputs=output_node, overwrite=True, max_trials=100\n",
    ")\n",
    "history= clf.fit(X_train, y_train, epochs=100, validation_data=(X_val, y_val)  )\n",
    "\n",
    "plt.plot(history.history['accuracy'])  \n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('English vs None-English accent accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "loss, acc = clf.evaluate(X_test, y_test, verbose=True)\n",
    "print('Accuracy: %.3f' % acc)\n",
    "model = clf.export_model()\n",
    "\n",
    "rows = np.array(X_test[0]).shape[0]\n",
    "cols = np.array(X_test[0]).shape[1]\n",
    "X_test = np.asarray(X_test).reshape(np.asarray(X_test).shape[0], rows, cols, 1 )\n",
    "y_test = y_test.astype(float)\n",
    "predictions =  np.argmax(model.predict(np.array(X_test).astype(float)), axis=1)\n",
    "\n",
    "\n",
    "\n",
    "print('test accuracy = ',accuracy_score(y_test, predictions))\n",
    "print('test precision = ',precision_score(y_test, predictions, average='weighted'))\n",
    "print('test recall = ',recall_score(y_test, predictions, average='weighted'))\n",
    "print('test f1 = ',f1_score(y_test, predictions, average='macro'))\n",
    "print('matthsew correlation = ',matthews_corrcoef(y_test, predictions))\n",
    "\n",
    "cf = confusion_matrix(y_test, predictions)\n",
    "ax= plt.subplot()\n",
    "sns.heatmap(cf, annot=True, fmt='g', ax=ax);  \n",
    "ax.set_xlabel('Predicted labels');ax.set_ylabel('True labels'); \n",
    "ax.set_title('Confusion Matrix'); \n",
    "ax.xaxis.set_ticklabels(['Arabic', 'English','French', 'Mandarin','Other','Spanish']); ax.yaxis.set_ticklabels(['Arabic', 'English','french', 'mandarin','other','spanish'], rotation=45);\n",
    "\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.save('autokeras_multi_EncoderDecoder2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-05T18:10:30.504896Z",
     "iopub.status.busy": "2021-09-05T18:10:30.504526Z",
     "iopub.status.idle": "2021-09-05T18:10:30.552403Z",
     "shell.execute_reply": "2021-09-05T18:10:30.551642Z",
     "shell.execute_reply.started": "2021-09-05T18:10:30.504863Z"
    }
   },
   "outputs": [],
   "source": [
    "model.save('autokeras_multi_EncoderDecoder_FINAL.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
